import uvicorn
from fastapi import FastAPI, HTTPException, Query, Depends
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from app.routers import securities, market, history
import httpx
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import asyncio
import logging
from app.dependencies import get_moex_client, MoexISSClient
from concurrent.futures import ThreadPoolExecutor
from confluent_kafka import Producer

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.
    - –ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ: –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç—ã
    - –ü—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ: –∑–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    """
    logger.info("üöÄ MOEX Proxy API –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    yield
    logger.info("üõë MOEX Proxy API –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è...")


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Kafka producer
def create_kafka_producer():
    try:
        kafka_broker = 'kafka:9093'
        producer = Producer({
        'bootstrap.servers': kafka_broker,
        'client.id': 'moex-proxy-api-producer',
        'acks': 'all',
        'retries': 5,
        'retry.backoff.ms': 1000,
        'enable.idempotence': True,
        'max.in.flight.requests.per.connection': 1,
        'linger.ms': 5,
        'batch.size': 16384,
        'socket.timeout.ms': 30000,
        'message.timeout.ms': 300000,
        'client.dns.lookup': 'use_all_dns_ips',
        'security.protocol': 'plaintext',
        })
        logger.info(f"Kafka producer created. bootstrap.servers={kafka_broker}, topic=candles")
    except Exception as e:
        logger.error(f"Error creating Kafka producer: {e}")
        raise e

    return producer


producer = create_kafka_producer()


# –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º –¥–ª—è Swagger
app = FastAPI(
    title="MOEX ISS Proxy API",
    description=""" 
    ## üì° –ü—Ä–æ–∫—Å–∏-API –∫ –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–µ (MOEX ISS)
    –≠—Ç–æ—Ç API —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–æ–º –∫ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–º—É API –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏ (ISS).
    """,
    version="1.0.0",
    contact={
        "name": "MOEX ISS Proxy API",
        "url": "https://www.moex.com/a2193",
    },
    license_info={
        "name": "MOEX ISS Terms of Use",
        "url": "https://www.moex.com/s116",
    },
    lifespan=lifespan,
    docs_url="/docs",  # Swagger UI
    redoc_url="/redoc",  # ReDoc –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
    openapi_tags=[
        {
            "name": "securities",
            "description": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ü–µ–Ω–Ω—ã—Ö –±—É–º–∞–≥–∞—Ö (–∞–∫—Ü–∏–∏, –æ–±–ª–∏–≥–∞—Ü–∏–∏, ETF –∏ —Ç.–¥.)",
        },
        {
            "name": "market",
            "description": "–¢–µ–∫—É—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–∫–æ—Ç–∏—Ä–æ–≤–∫–∏, —Å—Ç–∞–∫–∞–Ω—ã, —Å–¥–µ–ª–∫–∏)",
        },
        {
            "name": "history",
            "description": "–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (—Å–≤–µ—á–∏, –∏—Ç–æ–≥–∏ —Ç–æ—Ä–≥–æ–≤)",
        },
    ],
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í production –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ü–æ–¥–∫–ª—é—á–∞–µ–º —Ä–æ—É—Ç–µ—Ä—ã
app.include_router(securities.router)
app.include_router(market.router)
app.include_router(history.router)


# –ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç
@app.get("/", tags=["root"])
async def root():
    """
    –ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç API.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ—Ä–≤–∏—Å–µ –∏ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã.
    """
    return {
        "service": "MOEX ISS Proxy API",
        "description": "–ü—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏",
        "version": "1.0.0",
        "documentation": {
            "swagger": "/docs",
            "redoc": "/redoc",
            "openapi": "/openapi.json"
        },
    }


# –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –æ —Å–≤–µ—á–∞—Ö
@app.get("/candles/{security_id}")
async def get_candles(
        security_id: str,
        interval: int = Query(24, description="–ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–≤–µ—á–µ–π: 1 (1 –º–∏–Ω), 10 (10 –º–∏–Ω), 60 (1 —á–∞—Å), 24 (1 –¥–µ–Ω—å)"),
        from_date: str = Query(None, description="–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: 30 –¥–Ω–µ–π –Ω–∞–∑–∞–¥"),
        till_date: str = Query(None, description="–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: —Å–µ–≥–æ–¥–Ω—è"),
        limit: int = Query(100, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–µ—á–µ–π", ge=1, le=500),
        client: MoexISSClient = Depends(get_moex_client)
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –æ —Å–≤–µ—á–∞—Ö –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–π –±—É–º–∞–≥–∏.
    """
    logger.info(f"Fetching candles for {security_id} with params - from_date: {from_date}, till_date: {till_date}, "
                f"interval: {interval}, limit: {limit}")

    try:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if not from_date:
            from_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
        if not till_date:
            till_date = datetime.now().strftime("%Y-%m-%d")

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        params = {
            "interval": interval,
            "from": from_date,
            "till": till_date,
            "limit": limit,
        }

        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
        logger.info(f"Request parameters for {security_id}: {params}")

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        endpoint = f"engines/stock/markets/shares/boards/TQBR/securities/{security_id}/candles"
        data = await client.fetch_raw(endpoint, params)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        logger.info(f"Fetched data for {security_id}: {data}")

        return data  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

    except httpx.HTTPStatusError as e:
        logger.error(f"HTTP error while fetching candles for {security_id}: {e.response.text}")
        raise HTTPException(status_code=e.response.status_code, detail=f"–û—à–∏–±–∫–∞ API: {e.response.text}")
    except Exception as e:
        logger.error(f"Error while fetching candles for {security_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")


# –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ Kafka
@app.get("/process_and_analyze")
async def process_and_analyze_data(
        from_date: str = Query(None, description="–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: 30 –¥–Ω–µ–π –Ω–∞–∑–∞–¥"),
        till_date: str = Query(None, description="–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: —Å–µ–≥–æ–¥–Ω—è"),
        limit: int = Query(100, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–µ—á–µ–π", ge=1, le=500),
        interval: int = Query(24, description="–ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–≤–µ—á–µ–π: 1 (1 –º–∏–Ω), 10 (10 –º–∏–Ω), 60 (1 —á–∞—Å), 24 (1 –¥–µ–Ω—å)"),
):
    try:
        tickers = ["SBER", "GAZP", "LKOH", "YNDX", "NVTK"]
        data = []

        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        logger.info(f"Processing data with parameters - from_date: {from_date}, till_date: {till_date}, "
                    f"limit: {limit}, interval: {interval}")

        # –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ –∑–∞–¥–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if not from_date:
            from_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
        if not till_date:
            till_date = datetime.now().strftime("%Y-%m-%d")

        # –õ–æ–≥–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        logger.info(f"Using dates: from_date: {from_date}, till_date: {till_date}")

        # –í—ã—Ç—è–≥–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Å–≤–µ—á–∞—Ö –¥–ª—è –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        async with httpx.AsyncClient() as client:
            tasks = []
            for ticker in tickers:
                url = f"http://127.0.0.1:8000/candles/{ticker}?interval={interval}&from_date={from_date}&till_date={till_date}&limit={limit}"
                logger.info(f"Request URL for {ticker}: {url}")
                tasks.append(client.get(url))

            responses = await asyncio.gather(*tasks)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç—ã
            for response, ticker in zip(responses, tickers):
                if response.status_code == 200:
                    data.append(response.json())
                else:
                    logger.error(f"Failed to fetch data for ticker {ticker}, status code: {response.status_code}")
                    raise HTTPException(status_code=response.status_code, detail="Failed to fetch data")

        # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        logger.info(f"Fetched data for tickers: {tickers}")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –¥–ª—è –º–µ—Ç—Ä–∏–∫
        all_processed_data = []

        for ticker, ticker_data in zip(tickers, data):
            candles = ticker_data['candles']['data']
            if candles:
                # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–Ω—è
                for candle in candles:
                    open_price = candle[0]
                    close_price = candle[1]
                    high = candle[2]
                    low = candle[3]
                    value = candle[4]
                    volume = candle[5]
                    begin = candle[6]
                    end = candle[7]

                    # –í—ã—á–∏—Å–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                    sma = (open_price + close_price) / 2  # –ü—Ä–∏–º–µ—Ä –ø—Ä–æ—Å—Ç–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ SMA
                    std = high - low  # –ü—Ä–∏–º–µ—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
                    avg_price = (high + low) / 2  # –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞
                    close_to_open_ratio = (close_price - open_price) / open_price  # –û—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω—ã –∑–∞–∫—Ä—ã—Ç–∏—è –∫ —Ü–µ–Ω–µ –æ—Ç–∫—Ä—ã—Ç–∏—è

                    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ–±—ä–µ–∫—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–Ω—è
                    processed_candle = {
                        "ticker": ticker,
                        "openPrice": open_price,
                        "closePrice": close_price,
                        "openDt": begin,
                        "closeDt": end,
                        "sma": sma,
                        "std": std,
                        "avgPrice": avg_price,
                        "closeToOpenRatio": close_to_open_ratio
                    }

                    all_processed_data.append(processed_candle)

        # –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Kafka (–æ—Å—Ç–∞–≤–∏–º —á–∞—Å—Ç—å –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ –Ω–µ –∏–∑–º–µ–Ω—è–µ—Ç—Å—è)
        topic = "candles"
        for data in all_processed_data:
            producer.produce(topic, value=str(data))
            logger.info(f"Sent processed data to Kafka topic {topic}")

        # –ñ–¥–µ–º, –ø–æ–∫–∞ –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã
        producer.flush()

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        logger.info("Processed data successfully and sent to Kafka.")
        return {"processed_data": all_processed_data}

    except Exception as e:
        logger.error(f"Error processing and analyzing data: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))



# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫
def process_metrics(df, ticker):
    # –†–∞—Å—á–µ—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ (SMA)
    df["SMA"] = df[["open", "close"]].mean(axis=1)  # –°—Ä–µ–¥–Ω–µ–µ –º–µ–∂–¥—É —Ü–µ–Ω–æ–π –æ—Ç–∫—Ä—ã—Ç–∏—è –∏ –∑–∞–∫—Ä—ã—Ç–∏—è –∑–∞ –¥–µ–Ω—å

    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ (STD) ‚Äî —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Ü–µ–Ω–æ–π
    df["STD"] = df["high"] - df["low"]

    # –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –∑–∞ –¥–µ–Ω—å
    df["avg_price"] = (df["high"] + df["low"]) / 2

    # –û—Ç–Ω–æ—à–µ–Ω–∏–µ –º–µ–∂–¥—É —Ü–µ–Ω–æ–π –∑–∞–∫—Ä—ã—Ç–∏—è –∏ —Ü–µ–Ω–æ–π –æ—Ç–∫—Ä—ã—Ç–∏—è (Close to Open Ratio)
    df["close_to_open_ratio"] = (df["close"] - df["open"]) / df["open"]

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–ø–∏—Å–æ–∫ Python –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
    processed_data = df.to_dict(orient='records')

    # –î–æ–±–∞–≤–ª—è–µ–º ticker –∫ –¥–∞–Ω–Ω—ã–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    return {ticker: processed_data}


# –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host="127.0.0.1",
        port=8000,
        reload=True,
        log_level="info"
    )
